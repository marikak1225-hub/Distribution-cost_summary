import streamlit as st
import pandas as pd
import os
from io import BytesIO
from datetime import date
import altair as alt

st.set_page_config(layout="wide")
st.title("ğŸ“Š æœŸé–“ä¸­CVãƒ»é…ä¿¡è²»é›†è¨ˆãƒ„ãƒ¼ãƒ« + é ˜åŸŸåˆ¥ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³åˆ†æ")

@st.cache_data
def load_af_master(path):
    return pd.read_excel(path, usecols="B:D", header=1, engine="openpyxl")

af_path = "AFãƒã‚¹ã‚¿ãƒ¼.xlsx"
condition_path = "é ˜åŸŸåˆ¥ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³.xlsx"

# -------------------------
# AFãƒã‚¹ã‚¿ãƒ¼èª­ã¿è¾¼ã¿
# -------------------------
if not os.path.exists(af_path):
    st.error("AFãƒã‚¹ã‚¿ãƒ¼.xlsxãŒã‚¢ãƒ—ãƒªãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚Šã¾ã›ã‚“ã€‚é…ç½®ã—ã¦ãã ã•ã„ã€‚")
else:
    af_df = load_af_master(af_path)
    af_df.columns = ["AFã‚³ãƒ¼ãƒ‰", "åª’ä½“", "åˆ†é¡"]

    col1, col2 = st.columns(2)
    with col1:
        test_file = st.file_uploader("CVãƒ‡ãƒ¼ã‚¿ï¼ˆpublicã«å¤‰æ›´ï¼‰", type="xlsx", key="cv")
    with col2:
        cost_file = st.file_uploader("ã‚³ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆï¼ˆå¿…è¦ã‚·ãƒ¼ãƒˆãƒ»å¿…è¦è¡Œã®ã¿UP)", type="xlsx", key="cost")

    start_date, end_date = st.date_input("é›†è¨ˆæœŸé–“ã‚’é¸æŠ", value=(date(2025, 10, 1), date(2025, 10, 21)))

    if start_date > end_date:
        st.warning("âš ï¸ é–‹å§‹æ—¥ãŒçµ‚äº†æ—¥ã‚ˆã‚Šå¾Œã«ãªã£ã¦ã„ã¾ã™ã€‚")

    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:

        # -------------------------
        # CVãƒ‡ãƒ¼ã‚¿é›†è¨ˆ
        # -------------------------
        if test_file:
            st.subheader("ç”³è¾¼ãƒ‡ãƒ¼ã‚¿é›†è¨ˆçµæœ")
            test_df = pd.read_excel(test_file, header=0, engine="openpyxl")
            test_df["æ—¥ä»˜"] = pd.to_datetime(test_df.iloc[:, 0], format="%Y%m%d", errors="coerce")

            filtered = test_df[
                (test_df["æ—¥ä»˜"] >= pd.to_datetime(start_date)) &
                (test_df["æ—¥ä»˜"] <= pd.to_datetime(end_date))
            ]

            mapping = af_df.set_index("AFã‚³ãƒ¼ãƒ‰")["åª’ä½“"].to_dict()
            ad_codes = test_df.columns[1:]
            affiliate_prefixes = ["GEN", "AFA", "AFP", "RAA"]

            result_list = []
            for code in ad_codes:
                if any(code.startswith(prefix) for prefix in affiliate_prefixes):
                    media = "Affiliate"
                    category = "Affiliate"
                elif code in mapping:
                    media = mapping[code]
                    category = af_df.set_index("AFã‚³ãƒ¼ãƒ‰")["åˆ†é¡"].to_dict()[code]
                else:
                    continue

                cv_sum = filtered[code].sum()
                result_list.append({"åºƒå‘Šã‚³ãƒ¼ãƒ‰": code, "åª’ä½“": media, "åˆ†é¡": category, "CVåˆè¨ˆ": cv_sum})

            grouped = pd.DataFrame(result_list).groupby(["åˆ†é¡", "åª’ä½“"], as_index=False)["CVåˆè¨ˆ"].sum()
            st.dataframe(grouped)
            grouped.to_excel(writer, index=False, sheet_name="ç”³è¾¼ä»¶æ•°")

        # -------------------------
        # é…ä¿¡è²»é›†è¨ˆ
        # -------------------------
        if cost_file:
            st.subheader("é…ä¿¡è²»é›†è¨ˆçµæœ")

            xls = pd.ExcelFile(cost_file)
            target_sheets = [s for s in xls.sheet_names if any(k in s for k in ["Listing", "Display", "affiliate"])]

            for sheet in target_sheets:
                df = pd.read_excel(xls, sheet_name=sheet, engine="openpyxl")
                sheet_type = "Listing" if "Listing" in sheet else "Display" if "Display" in sheet else "Affiliate"
                date_col_index = 1 if sheet_type in ["Listing", "Display"] else 0

                df.iloc[:, date_col_index] = pd.to_datetime(df.iloc[:, date_col_index], errors='coerce')
                filtered_df = df[
                    (df.iloc[:, date_col_index] >= pd.to_datetime(start_date)) &
                    (df.iloc[:, date_col_index] <= pd.to_datetime(end_date))
                ]

                if sheet_type == "Listing":
                    columns_to_sum = {
                        "Listing ALL": 17, "Googleå˜ä½“": 53, "Googleå˜ä½“ä»¥å¤–": 89, "Googleãã®ä»–": 125,
                        "Yahooå˜ä½“": 161, "Yahooå˜ä½“ä»¥å¤–": 197, "Microsoftå˜ä½“": 233, "Microsoftå˜ä½“ä»¥å¤–": 269
                    }
                    desired_order = [
                        "Listing ALL", "Googleãã®ä»–", "Googleå˜ä½“", "Googleå˜ä½“ä»¥å¤–",
                        "Yahooå˜ä½“", "Yahooå˜ä½“ä»¥å¤–", "Microsoftå˜ä½“", "Microsoftå˜ä½“ä»¥å¤–"
                    ]
                elif sheet_type == "Display":
                    columns_to_sum = {
                        "Display ALL": 17, "Meta": 53, "X": 89, "LINE": 125, "YDA": 161,
                        "TTD": 199, "TikTok": 235, "GDN": 271, "CRITEO": 307, "RUNA": 343
                    }
                    desired_order = None
                else:
                    columns_to_sum = {"AFF ALL": 20}
                    desired_order = None

                daily_rows = []
                for label, col_index in columns_to_sum.items():
                    try:
                        temp_df = filtered_df[[filtered_df.columns[date_col_index], filtered_df.columns[col_index]]].copy()
                        temp_df.columns = ["æ—¥ä»˜", "é‡‘é¡"]
                        temp_df["é …ç›®"] = label
                        daily_rows.append(temp_df)
                    except Exception:
                        continue

                if daily_rows:
                    daily_df = pd.concat(daily_rows)
                    daily_grouped = daily_df.groupby(["æ—¥ä»˜", "é …ç›®"], as_index=False)["é‡‘é¡"].sum()
                    daily_grouped["æ—¥ä»˜"] = pd.to_datetime(daily_grouped["æ—¥ä»˜"]).dt.strftime("%Y/%m/%d")
                    daily_grouped = daily_grouped.sort_values(by=["é …ç›®", "æ—¥ä»˜"])

                    pivot_df = daily_grouped.pivot(index="æ—¥ä»˜", columns="é …ç›®", values="é‡‘é¡").fillna(0)

                    if desired_order:
                        ordered_cols = [col for col in desired_order if col in pivot_df.columns]
                        pivot_df = pivot_df[ordered_cols]

                    if not pivot_df.empty and len(pivot_df.columns) > 0:
                        pivot_df.loc["åˆè¨ˆ"] = pivot_df.sum(numeric_only=True)

                    st.subheader(f"{sheet} ã®é›†è¨ˆçµæœ")
                    col_table, col_chart = st.columns([1, 1.5])
                    with col_table:
                        st.dataframe(pivot_df)

                    with col_chart:
                        chart = alt.Chart(daily_grouped).mark_line().encode(
                            x="æ—¥ä»˜:T",
                            y="é‡‘é¡:Q",
                            color="é …ç›®:N"
                        ).properties(width=500, height=300)
                        st.altair_chart(chart, use_container_width=True)

                    pivot_df.to_excel(writer, sheet_name=f"{sheet_type}_é›†è¨ˆ")

    output.seek(0)
    st.download_button(
        label="ğŸ“¥ å…¨é›†è¨ˆExcelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=output.getvalue(),
        file_name=f"ç”³è¾¼ä»¶æ•°é…ä¿¡è²»é›†è¨ˆ_{start_date.strftime('%Y%m%d')}_{end_date.strftime('%Y%m%d')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

# -------------------------
# é ˜åŸŸåˆ¥ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³åˆ†æ
# -------------------------
st.subheader("ğŸ“ˆ é ˜åŸŸåˆ¥ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³åˆ†æ")
if os.path.exists(condition_path):
    cond_df = pd.read_excel(condition_path, sheet_name="é ˜åŸŸåˆ¥ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³", header=None)

    # ALLãƒ‡ãƒ¼ã‚¿
    all_section = cond_df.iloc[4:30, [1, 3, 4, 7, 8]]
    all_section.columns = ["é€±", "ä»¶æ•°", "ä»¶æ•°å¤‰åŒ–ç‡", "CPA", "CPAå¤‰åŒ–ç‡"]

    # AFF & SEMãƒ‡ãƒ¼ã‚¿
    aff_sem_section = cond_df.iloc[33:59, [1, 3, 4, 7, 8, 10, 12, 13, 16]]
    aff_sem_section.columns = ["AFFé€±", "AFFä»¶æ•°", "AFFå¤‰åŒ–ç‡", "AFFCPA", "AFFCPAå¤‰åŒ–ç‡",
                                "SEMé€±", "SEMä»¶æ•°", "SEMå¤‰åŒ–ç‡", "SEMCPAå¤‰åŒ–ç‡"]

    # ã‚½ãƒ¼ãƒˆé †
    week_order = sorted(all_section["é€±"].dropna().unique(), key=lambda x: int(x.replace("ç§»ç®¡å¾Œ", "").replace("W", "")))

    option = st.selectbox("è¡¨ç¤ºã™ã‚‹é ˜åŸŸ", ["å…¨ä½“", "AFF", "SEM"])

    charts = {}

    if option == "å…¨ä½“":
        # ã‚°ãƒ©ãƒ•â‘ : AFFä»¶æ•°ãƒ»SEMä»¶æ•° (å¡—ã‚Šã¤ã¶ã—) + AFFå¤‰åŒ–ç‡ãƒ»SEMå¤‰åŒ–ç‡ (æŠ˜ã‚Œç·š)
        aff_sem_melt = pd.DataFrame({
            "é€±": aff_sem_section["AFFé€±"],
            "AFFä»¶æ•°": aff_sem_section["AFFä»¶æ•°"],
            "AFFå¤‰åŒ–ç‡": aff_sem_section["AFFå¤‰åŒ–ç‡"],
            "SEMä»¶æ•°": aff_sem_section["SEMä»¶æ•°"],
            "SEMå¤‰åŒ–ç‡": aff_sem_section["SEMå¤‰åŒ–ç‡"]
        })

        base = alt.Chart(aff_sem_melt).encode(x=alt.X("é€±:N", sort=week_order))
        area_aff = base.mark_area(opacity=0.4, color="blue").encode(y="AFFä»¶æ•°:Q")
        area_sem = base.mark_area(opacity=0.4, color="green").encode(y="SEMä»¶æ•°:Q")
        line_aff = base.mark_line(color="blue").encode(y="AFFå¤‰åŒ–ç‡:Q")
        line_sem = base.mark_line(color="green").encode(y="SEMå¤‰åŒ–ç‡:Q")
        charts["ã‚°ãƒ©ãƒ•â‘ "] = alt.layer(area_aff, area_sem, line_aff, line_sem).resolve_scale(y='independent')

        # ã‚°ãƒ©ãƒ•â‘¡: CV ALL ä»¶æ•° vs å¤‰åŒ–ç‡
        base_all = alt.Chart(all_section).encode(x=alt.X("é€±:N", sort=week_order))
        bar_cv = base_all.mark_bar(color="steelblue").encode(y="ä»¶æ•°:Q")
        line_cv = base_all.mark_line(color="orange").encode(y="ä»¶æ•°å¤‰åŒ–ç‡:Q")
        charts["ã‚°ãƒ©ãƒ•â‘¡"] = alt.layer(bar_cv, line_cv).resolve_scale(y='independent')

        # ã‚°ãƒ©ãƒ•â‘¢: CPA ALL vs å¤‰åŒ–ç‡
        bar_cpa = base_all.mark_bar(color="purple").encode(y="CPA:Q")
        line_cpa = base_all.mark_line(color="orange").encode(y="CPAå¤‰åŒ–ç‡:Q")
        charts["ã‚°ãƒ©ãƒ•â‘¢"] = alt.layer(bar_cpa, line_cpa).resolve_scale(y='independent')

        st.altair_chart(charts["ã‚°ãƒ©ãƒ•â‘ "], use_container_width=True)
        st.altair_chart(charts["ã‚°ãƒ©ãƒ•â‘¡"], use_container_width=True)
        st.altair_chart(charts["ã‚°ãƒ©ãƒ•â‘¢"], use_container_width=True)

    elif option == "AFF":
        base_aff = alt.Chart(aff_sem_section).encode(x=alt.X("AFFé€±:N", sort=week_order))
        bar_aff_cv = base_aff.mark_bar(color="steelblue").encode(y="AFFä»¶æ•°:Q")
        line_aff_cv = base_aff.mark_line(color="orange").encode(y="AFFå¤‰åŒ–ç‡:Q")
        st.altair_chart(alt.layer(bar_aff_cv, line_aff_cv).resolve_scale(y='independent'), use_container_width=True)

        bar_aff_cpa = base_aff.mark_bar(color="purple").encode(y="AFFCPA:Q")
        line_aff_cpa = base_aff.mark_line(color="orange").encode(y="AFFCPAå¤‰åŒ–ç‡:Q")
        st.altair_chart(alt.layer(bar_aff_cpa, line_aff_cpa).resolve_scale(y='independent'), use_container_width=True)

    else:
        base_sem = alt.Chart(aff_sem_section).encode(x=alt.X("SEMé€±:N", sort=week_order))
        bar_sem_cv = base_sem.mark_bar(color="steelblue").encode(y="SEMä»¶æ•°:Q")
        line_sem_cv = base_sem.mark_line(color="orange").encode(y="SEMå¤‰åŒ–ç‡:Q")
        st.altair_chart(alt.layer(bar_sem_cv, line_sem_cv).resolve_scale(y='independent'), use_container_width=True)

        bar_sem_cpa = base_sem.mark_bar(color="purple").encode(y="SEMCPAå¤‰åŒ–ç‡:Q")
        line_sem_cpa = base_sem.mark_line(color="orange").encode(y="SEMCPAå¤‰åŒ–ç‡:Q")
        st.altair_chart(alt.layer(bar_sem_cpa, line_sem_cpa).resolve_scale(y='independent'), use_container_width=True)
else:
    st.warning("é ˜åŸŸåˆ¥ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³.xlsxãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚GitHubã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")