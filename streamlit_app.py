import streamlit as st
import pandas as pd
import os
from io import BytesIO
from datetime import date
import altair as alt

st.set_page_config(layout="wide")
st.title("ğŸ“Š æœŸé–“ä¸­CVãƒ»é…ä¿¡è²»é›†è¨ˆãƒ„ãƒ¼ãƒ«")

@st.cache_data
def load_af_master(path):
    return pd.read_excel(path, usecols="B:D", header=1, engine="openpyxl")

af_path = "AFãƒã‚¹ã‚¿ãƒ¼.xlsx"
if not os.path.exists(af_path):
    st.error("AFãƒã‚¹ã‚¿ãƒ¼.xlsxãŒã‚¢ãƒ—ãƒªãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚Šã¾ã›ã‚“ã€‚é…ç½®ã—ã¦ãã ã•ã„ã€‚")
else:
    af_df = load_af_master(af_path)
    af_df.columns = ["AFã‚³ãƒ¼ãƒ‰", "åª’ä½“", "åˆ†é¡"]

    col1, col2 = st.columns(2)
    with col1:
        test_file = st.file_uploader("CVãƒ‡ãƒ¼ã‚¿ï¼ˆpublicã«å¤‰æ›´ï¼‰", type="xlsx", key="cv")
    with col2:
        cost_file = st.file_uploader("ã‚³ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆï¼ˆå¿…è¦ã‚·ãƒ¼ãƒˆãƒ»å¿…è¦è¡Œã®ã¿UP)", type="xlsx", key="cost")

    start_date, end_date = st.date_input("é›†è¨ˆæœŸé–“ã‚’é¸æŠ", value=(date(2025, 10, 1), date(2025, 10, 21)))

    if start_date > end_date:
        st.warning("âš ï¸ é–‹å§‹æ—¥ãŒçµ‚äº†æ—¥ã‚ˆã‚Šå¾Œã«ãªã£ã¦ã„ã¾ã™ã€‚")

    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:

        # -------------------------
        # CVãƒ‡ãƒ¼ã‚¿é›†è¨ˆ
        # -------------------------
        if test_file:
            st.subheader("ç”³è¾¼ãƒ‡ãƒ¼ã‚¿é›†è¨ˆçµæœ")
            test_df = pd.read_excel(test_file, header=0, engine="openpyxl")
            test_df["æ—¥ä»˜"] = pd.to_datetime(test_df.iloc[:, 0], format="%Y%m%d", errors="coerce")

            filtered = test_df[
                (test_df["æ—¥ä»˜"] >= pd.to_datetime(start_date)) &
                (test_df["æ—¥ä»˜"] <= pd.to_datetime(end_date))
            ]

            mapping = af_df.set_index("AFã‚³ãƒ¼ãƒ‰")[["åª’ä½“", "åˆ†é¡"]].to_dict("index")
            ad_codes = test_df.columns[1:]
            affiliate_prefixes = ["GEN", "AFA", "AFP", "RAA"]

            result_list = []
            for code in ad_codes:
                if any(code.startswith(prefix) for prefix in affiliate_prefixes):
                    media = "Affiliate"
                    category = "Affiliate"
                elif code in mapping:
                    media = mapping[code]["åª’ä½“"]
                    category = mapping[code]["åˆ†é¡"]
                else:
                    continue

                cv_sum = filtered[code].sum()
                result_list.append({"åºƒå‘Šã‚³ãƒ¼ãƒ‰": code, "åª’ä½“": media, "åˆ†é¡": category, "CVåˆè¨ˆ": cv_sum})

            grouped = pd.DataFrame(result_list).groupby(["åˆ†é¡", "åª’ä½“"], as_index=False)["CVåˆè¨ˆ"].sum()
            st.dataframe(grouped)
            grouped.to_excel(writer, index=False, sheet_name="ç”³è¾¼ä»¶æ•°")

        # -------------------------
        # é…ä¿¡è²»é›†è¨ˆï¼ˆãƒ”ãƒœãƒƒãƒˆï¼‹ã‚°ãƒ©ãƒ•ï¼‰
        # -------------------------
        if cost_file:
            st.subheader("é…ä¿¡è²»é›†è¨ˆçµæœ")

            # âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’ã“ã“ã«é…ç½®
            output.seek(0)
            st.download_button(
                label="ğŸ“¥ å…¨é›†è¨ˆExcelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=output.getvalue(),
                file_name=f"ç”³è¾¼ä»¶æ•°é…ä¿¡è²»é›†è¨ˆ_{start_date.strftime('%Y%m%d')}_{end_date.strftime('%Y%m%d')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

            xls = pd.ExcelFile(cost_file)
            target_sheets = [s for s in xls.sheet_names if any(k in s for k in ["Listing", "Display", "affiliate"])]

            for sheet in target_sheets:
                df = pd.read_excel(xls, sheet_name=sheet, engine="openpyxl")
                sheet_type = "Listing" if "Listing" in sheet else "Display" if "Display" in sheet else "Affiliate"
                date_col_index = 1 if sheet_type in ["Listing", "Display"] else 0

                df.iloc[:, date_col_index] = pd.to_datetime(df.iloc[:, date_col_index], errors='coerce')
                filtered_df = df[
                    (df.iloc[:, date_col_index] >= pd.to_datetime(start_date)) &
                    (df.iloc[:, date_col_index] <= pd.to_datetime(end_date))
                ]

                if sheet_type == "Listing":
                    columns_to_sum = {
                        "Listing ALL": 17, "Googleå˜ä½“": 53, "Googleå˜ä½“ä»¥å¤–": 89, "Googleãã®ä»–": 125,
                        "Yahooå˜ä½“": 161, "Yahooå˜ä½“ä»¥å¤–": 197, "Microsoftå˜ä½“": 233, "Microsoftå˜ä½“ä»¥å¤–": 269
                    }
                    desired_order = [
                        "Listing ALL", "Googleãã®ä»–", "Googleå˜ä½“", "Googleå˜ä½“ä»¥å¤–",
                        "Yahooå˜ä½“", "Yahooå˜ä½“ä»¥å¤–", "Microsoftå˜ä½“", "Microsoftå˜ä½“ä»¥å¤–"
                    ]
                elif sheet_type == "Display":
                    columns_to_sum = {
                        "Display ALL": 17, "Meta": 53, "X": 89, "LINE": 125, "YDA": 161,
                        "TTD": 199, "TikTok": 235, "GDN": 271, "CRITEO": 307, "RUNA": 343
                    }
                    desired_order = None
                else:
                    columns_to_sum = {"AFF ALL": 20}
                    desired_order = None

                daily_rows = []
                for label, col_index in columns_to_sum.items():
                    try:
                        temp_df = filtered_df[[filtered_df.columns[date_col_index], filtered_df.columns[col_index]]].copy()
                        temp_df.columns = ["æ—¥ä»˜", "é‡‘é¡"]
                        temp_df["é …ç›®"] = label
                        daily_rows.append(temp_df)
                    except Exception:
                        continue

                if daily_rows:
                    daily_df = pd.concat(daily_rows)
                    daily_grouped = daily_df.groupby(["æ—¥ä»˜", "é …ç›®"], as_index=False)["é‡‘é¡"].sum()
                    daily_grouped["æ—¥ä»˜"] = pd.to_datetime(daily_grouped["æ—¥ä»˜"]).dt.strftime("%Y/%m/%d")
                    daily_grouped = daily_grouped.sort_values(by=["é …ç›®", "æ—¥ä»˜"])

                    pivot_df = daily_grouped.pivot(index="æ—¥ä»˜", columns="é …ç›®", values="é‡‘é¡").fillna(0)

                    # ä¸¦ã³é †ã®æŒ‡å®šï¼ˆListingã®ã¿ï¼‰
                    if desired_order:
                        ordered_cols = [col for col in desired_order if col in pivot_df.columns]
                        pivot_df = pivot_df[ordered_cols]

                    # âœ… åˆè¨ˆè¡Œã‚’è¿½åŠ ï¼ˆåˆ—ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
                    if not pivot_df.empty and len(pivot_df.columns) > 0:
                        pivot_df.loc["åˆè¨ˆ"] = pivot_df.sum(numeric_only=True)

                    st.subheader(f"{sheet} ã®é›†è¨ˆçµæœ")
                    col_table, col_chart = st.columns([1, 1.5])
                    with col_table:
                        st.dataframe(pivot_df)

                    with col_chart:
                        chart = alt.Chart(daily_grouped).mark_line().encode(
                            x="æ—¥ä»˜:T",
                            y="é‡‘é¡:Q",
                            color="é …ç›®:N"
                        ).properties(width=500, height=300)
                        st.altair_chart(chart, use_container_width=True)

                    pivot_df.to_excel(writer, sheet_name=f"{sheet_type}_é›†è¨ˆ")